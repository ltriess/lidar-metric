<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script type="text/javascript">
	// Copy text to clipboard
	function copyToClipboard(element) {
		var $temp = $("<textarea>");
		$("body").append($temp);
		$temp.val($(element).text()).select();
		document.execCommand("copy");
		$temp.remove();
	}
</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:17px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
        font-size: 30px;
	}

	a:link,a:visited {
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	.img-zoom {
		transition: transform .2s;
	}

	.img-zoom:hover {
		transform: scale(1.05);
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
		transition: transform .2s;
	}

	.layered-paper-big:hover {
		transform: scale(1.05);
	}

	hr {
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

    table td, table td * {
        vertical-align: top;
    }

    pre code {
		background-color: #eee;
		border: 1px solid #999;
		display: block;
		padding: 20px;
		font-family: monospace;
	}
</style>

<html lang="en">
	<head>
		<meta charset="utf-8">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-48GMP530ET"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-48GMP530ET');
        </script>

		<title>A Survey on Deep Domain Adaptation for LiDAR Perception</title>
		<link rel="icon" href="https://larissa.triess.eu/lidar-metric/images/overview.svg">
		<meta property="og:image" content="https://larissa.triess.eu/lidar-metric/images/overview.svg"/>
		<meta property="og:title" content="Quantifying point cloud realism through adversarially learned latent representations"/>
		<meta property="og:description" content="Project page for 'Quantifying point cloud realism through adversarially learned latent representations' with links to the paper."/>
		<meta property="og:keywords" content="lidar, point cloud, metric, machine learning, deep learning, realism measure"/>
		<meta property="og:author" content="Larissa Triess"/>
	</head>

	<body>
		<br>
		<!-------------------------------- HEADLINE -------------------------------->
		<div style="text-align: center;">
			<!-------------------------------- TITLE -------------------------------->
			<span style="font-size:36px">Quantifying point cloud realism<br>through adversarially learned latent representations</span><br><br>
			<br>

			<!-------------------------------- AUTHORS -------------------------------->
			<table style="width: 960px; text-align: center; margin-left:auto; margin-right:auto">
				<tr>
				<td>
					<span style="font-size:20px"><a href="https://larissa.triess.eu">Larissa T. Triess</a><sup>1,2</sup></span>
				</td>
				<td>
					<span style="font-size:20px"><a href="https://david-peter.de">David Peter</a><sup>1</sup></span>
				</td>
				<td>
					<span style="font-size:20px"><a href="https://baurst.github.io">Stefan A. Baur</a><sup>1</sup></span>
				</td>
				<td>
					<span style="font-size:20px"><a href="https://www.aifb.kit.edu/web/J._Marius_Z%C3%B6llner">J. Marius ZÃ¶llner</a><sup>2,3</sup></span>
				</td>
				</tr>
			</table>
			<br>

			<!-------------------------------- AFFILIATIONS -------------------------------->
			<table style="width: 960px; text-align: center; margin-left:auto; margin-right:auto">
				<tr>
				<td>
					<span style="font-size:18px"><sup>1</sup>Mercedes-Benz AG<br>Stuttgart (Germany)</span>
				</td>
				<td>
					<span style="font-size:18px"><sup>2</sup>Karlsruhe Institute of Technology<br>Karlsruhe (Germany)</span>
				</td>
				<td>
					<span style="font-size:18px"><sup>3</sup>Research Center for Information Technology<br>Karlsruhe (Germany)</span>
				</td>
				</tr>
			</table>
			<br>

			<!-------------------------------- CONFERENCE -------------------------------->
			<table style="width: 960px; text-align: center; margin-left:auto; margin-right:auto">
				<tr>
				<td>
					<span style="font-size:18px">In 2021 German Conference on Pattern Recognition (GCPR)</span>
				</td>
				</tr>
			</table>
			<br>

			<!-------------------------------- RESOURCES -------------------------------->
			<table style="width: 960px; text-align: center; margin-left:auto; margin-right:auto">
				<tr>
				<td>
					<span style="font-size:24px"><a href="https://arxiv.org/abs/2109.11775">[Paper]</a></span>
					<span style="font-size:24px"><a href="https://youtu.be/81KmoFiC0co">[Video]</a></span>
				</td>
				</tr>
			</table>
        </div>

        <br>
        <br>
        <!-------------------------------- TEASER IMAGE -------------------------------->
        <table style="width: 960px; text-align: center; margin-left:auto; margin-right:auto">
            <tr>
                <td style="padding: 10px">
                    <a href="images/overview.svg">
                        <img class="img-zoom" src="images/overview.svg" width="60%" alt="metric"/>
                    </a>
                </td>
            </tr>
        </table>

        <table style="width: 960px; text-align: center; margin-left:auto; margin-right:auto">
			<tr>
				<center>
					<td style="font-size:14px">
						<i>
							<b>Proposed Approach</b>:<br>
							The realism measure has a tripartite understanding of the 3D-world, schematically illustrated on the bottom left.
							The other images show the color-coded metric scores at discrete query point locations (gray circles).
							Local regions in the simulated sample (top left) are largely predicted as being of synthetic origin (blue), while regions in the real-world sample (top right) are predicted as being realistic (green).
							The bottom right image shows a GAN-generated sample which has large areas with high distortion levels that neither appear realistic nor synthetic.
							The metric therefore assigns high misc scores (red).
						</i>
					</td>
				</center>
			</tr>
		</table>

		<br>
		<br>
		<hr><!-------------------------------- ABSTRACT -------------------------------->

		<div id="abstract" style="text-align: center;"><h1>Abstract</h1></div>

		<table style="width: 960px; text-align: left; margin-left:auto; margin-right:auto">
			<tr>
			<td>
				Judging the quality of samples synthesized by generative models can be tedious and time consuming, especially for complex data structures, such as point clouds.
				This paper presents a novel approach to quantify the realism of local regions in LiDAR point clouds.
				Relevant features are learned from real-world and synthetic point clouds by training on a proxy classification task.
				Inspired by fair networks, we use an adversarial technique to discourage the encoding of dataset-specific information.
				The resulting metric can assign a quality score to samples without requiring any task specific annotations.
				<br><br>
				In a series of experiments, we confirm the soundness of our metric by applying it in controllable task setups and on unseen data.
				Additional experiments show reliable interpolation capabilities of the metric between data with varying degree of realism.
				As one important application, we demonstrate how the local realism score can be used for anomaly detection in point clouds.
			</td>
			</tr>
		</table>

		<br>
		<br>
		<hr><!-------------------------------- PAPER -------------------------------->
		<div id="paper" style="text-align: center;"><h1>Paper</h1></div>

		<div style="text-align: center;">
			<span><a href="https://arxiv.org/abs/2109.11775"><img class="layered-paper-big" style="height:250px" src="./images/paper_thumb.png" alt=""/></a></span>
			<br><br><br><br>
			<span style="font-size:20pt">Paper: <a href="https://arxiv.org/abs/2109.11775">[ArXiv]</a></span>
		</div>
		<br>
		<div style="text-align: center;">
			<span style="font-size:18pt">
				Citation:
				<button type="button" onclick="copyToClipboard('#bibtex')">Copy</button>
				<button type="button" onclick="window.open('./resources/triess2021gcpr.bib')">Download</button>
			</span>
<!---------><pre><code id="bibtex" style="width: 960px; text-align: left; margin-left:auto; margin-right:auto">@inproceedings{triess2021gcpr,
<!--------->  title = {
<!--------->	Quantifying point cloud realism through adversarially learned latent representations
<!--------->  },
<!--------->  author = {
<!--------->    Larissa T. Triess and David Peter and Stefan A. Baur and J. Marius Z\"ollner
<!--------->  },
<!--------->  booktitle = {Proc. of the German Conference on Pattern Recognition (GCPR)},
<!--------->  year = {2021},
<!--------->}</code></pre>
		</div>

		<br>
		<br>
		<hr><!-------------------------------- CONTRIBUTIONS -------------------------------->

		<div id="contributions" style="text-align: center;"><h1>Contributions</h1></div>

		<table style="width: 960px; text-align: left; margin-left:auto; margin-right:auto">
			<tr>
			<td>
				The aim of this paper is to provide a reliable metric that gives a quantitative estimate about the realism of generated LiDAR data.
				The contributions of this work are threefold.
				First and foremost, we present a novel way to learn a measure of realism in point clouds.
				This is achieved by learning hierarchical point set features on a proxy classification task.
				Second, we utilize an adversarial technique from the fairness-in-machine-learning domain in order to eliminate dataset-specific information.
				This allows the measure to be used on unseen datasets.
				Finally, we demonstrate how the fine-grained local realism score can be used for anomaly detection in LiDAR scans.
			</td>
			</tr>
		</table>

		<br>
		<br>
		<hr><!-------------------------------- ACKNOWLEDGEMENTS -------------------------------->

		<div id="acknowledgements" style="text-align: center;"><h1>Acknowledgements</h1></div>

		<table style="width: 960px; text-align: left; margin-left:auto; margin-right:auto">
			<tr>
			<td>
				The research leading to these results is funded by the German Federal Ministry for Economic Affairs and Energy within the project "KI Delta Learning" (FÃ¶rderkennzeichen 19A19013A).
			</td>
			</tr>
		</table>

		<br>
		<br>

	</body>
</html>
